{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7232811,"sourceType":"datasetVersion","datasetId":4188143}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2023-12-19T18:26:47.608505Z","iopub.execute_input":"2023-12-19T18:26:47.609189Z","iopub.status.idle":"2023-12-19T18:26:49.043792Z","shell.execute_reply.started":"2023-12-19T18:26:47.609154Z","shell.execute_reply":"2023-12-19T18:26:49.042857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# The Task\nTrain several models of recurrent neural networks, for example LSTM, GRU, Bidirectional-LSTM.\nCalculate the value of the metric that you proposed in Part 1 and compare the results for different RN, heuristics, and classical ML.","metadata":{}},{"cell_type":"markdown","source":"### Read the preprocessed data","metadata":{}},{"cell_type":"code","source":"data = pd.read_parquet('/kaggle/input/normalized-tweets/Tweets.parquet', engine='pyarrow')","metadata":{"execution":{"iopub.status.busy":"2023-12-19T18:26:49.045826Z","iopub.execute_input":"2023-12-19T18:26:49.046313Z","iopub.status.idle":"2023-12-19T18:26:49.468148Z","shell.execute_reply.started":"2023-12-19T18:26:49.046278Z","shell.execute_reply":"2023-12-19T18:26:49.466701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check the loaded data","metadata":{}},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2023-12-19T18:26:49.469552Z","iopub.execute_input":"2023-12-19T18:26:49.469886Z","iopub.status.idle":"2023-12-19T18:26:49.502333Z","shell.execute_reply.started":"2023-12-19T18:26:49.469860Z","shell.execute_reply":"2023-12-19T18:26:49.501298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.sample(10)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T18:26:49.503509Z","iopub.execute_input":"2023-12-19T18:26:49.503827Z","iopub.status.idle":"2023-12-19T18:26:49.524086Z","shell.execute_reply.started":"2023-12-19T18:26:49.503802Z","shell.execute_reply":"2023-12-19T18:26:49.523122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Everethig looks fine, so we can start to train our models.","metadata":{}},{"cell_type":"markdown","source":"# Sinmple Linear Model\nLet's start with  simple linear model with pytorch.","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchtext.data import get_tokenizer\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nimport torch.nn.functional as F\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords","metadata":{"execution":{"iopub.status.busy":"2023-12-19T18:26:49.527331Z","iopub.execute_input":"2023-12-19T18:26:49.527698Z","iopub.status.idle":"2023-12-19T18:26:54.763413Z","shell.execute_reply.started":"2023-12-19T18:26:49.527664Z","shell.execute_reply":"2023-12-19T18:26:54.762670Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Check device, and save the information about it","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T18:26:54.764391Z","iopub.execute_input":"2023-12-19T18:26:54.764871Z","iopub.status.idle":"2023-12-19T18:26:54.830250Z","shell.execute_reply.started":"2023-12-19T18:26:54.764843Z","shell.execute_reply":"2023-12-19T18:26:54.829341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Tokenization and text preprocessing","metadata":{}},{"cell_type":"code","source":"stop_words = set(stopwords.words('english'))\n\ndef preprocess_text(text):\n    # Tokenize the text\n    tokens = word_tokenize(text)\n    # Remove stopwords\n    tokens = [word.lower() for word in tokens if word.isalpha() and word.lower() not in stop_words]\n    return ' '.join(tokens)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T18:26:54.831526Z","iopub.execute_input":"2023-12-19T18:26:54.831888Z","iopub.status.idle":"2023-12-19T18:26:54.852510Z","shell.execute_reply.started":"2023-12-19T18:26:54.831854Z","shell.execute_reply":"2023-12-19T18:26:54.851656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Apply preprocessing to the 'Text' column","metadata":{}},{"cell_type":"code","source":"data['Processed_Text'] = data['Normalized_Text'].apply(preprocess_text)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T18:26:54.853577Z","iopub.execute_input":"2023-12-19T18:26:54.853938Z","iopub.status.idle":"2023-12-19T18:27:04.855187Z","shell.execute_reply.started":"2023-12-19T18:26:54.853913Z","shell.execute_reply":"2023-12-19T18:27:04.854435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Encode labels using LabelEncoder","metadata":{}},{"cell_type":"code","source":"label_encoder = LabelEncoder()\ndata['Sentiment_encoded'] = label_encoder.fit_transform(data['Sentiment'])","metadata":{"execution":{"iopub.status.busy":"2023-12-19T18:27:04.856598Z","iopub.execute_input":"2023-12-19T18:27:04.856954Z","iopub.status.idle":"2023-12-19T18:27:04.872153Z","shell.execute_reply.started":"2023-12-19T18:27:04.856923Z","shell.execute_reply":"2023-12-19T18:27:04.871278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Split the data into train, test, and validation sets","metadata":{}},{"cell_type":"code","source":"train_df, test_df = train_test_split(data, test_size=0.2, random_state=42)\ntrain_df, valid_df = train_test_split(train_df, test_size=0.2, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-19T18:27:04.873468Z","iopub.execute_input":"2023-12-19T18:27:04.873775Z","iopub.status.idle":"2023-12-19T18:27:04.915564Z","shell.execute_reply.started":"2023-12-19T18:27:04.873752Z","shell.execute_reply":"2023-12-19T18:27:04.914725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Vectorize the text data","metadata":{}},{"cell_type":"code","source":"vectorizer = CountVectorizer()\nX_train_vec = vectorizer.fit_transform(train_df['Normalized_Text'])\nX_test_vec = vectorizer.transform(test_df['Normalized_Text'])\nX_valid_vec = vectorizer.transform(valid_df['Normalized_Text'])","metadata":{"execution":{"iopub.status.busy":"2023-12-19T18:27:04.916768Z","iopub.execute_input":"2023-12-19T18:27:04.917652Z","iopub.status.idle":"2023-12-19T18:27:06.072811Z","shell.execute_reply.started":"2023-12-19T18:27:04.917599Z","shell.execute_reply":"2023-12-19T18:27:06.072052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Convert data to PyTorch tensors","metadata":{}},{"cell_type":"code","source":"X_train_tensor = torch.tensor(X_train_vec.toarray(), dtype=torch.float32).to(device)\nX_test_tensor = torch.tensor(X_test_vec.toarray(), dtype=torch.float32).to(device)\nX_valid_tensor = torch.tensor(X_valid_vec.toarray(), dtype=torch.float32).to(device)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-19T18:27:06.073961Z","iopub.execute_input":"2023-12-19T18:27:06.074312Z","iopub.status.idle":"2023-12-19T18:27:15.563319Z","shell.execute_reply.started":"2023-12-19T18:27:06.074279Z","shell.execute_reply":"2023-12-19T18:27:15.562551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Convert labels to PyTorch tensors","metadata":{}},{"cell_type":"code","source":"y_train_tensor = torch.tensor(train_df['Sentiment_encoded'].values, dtype=torch.long).to(device)\ny_test_tensor = torch.tensor(test_df['Sentiment_encoded'].values, dtype=torch.long).to(device)\ny_valid_tensor = torch.tensor(valid_df['Sentiment_encoded'].values, dtype=torch.long).to(device)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T18:27:15.564392Z","iopub.execute_input":"2023-12-19T18:27:15.564677Z","iopub.status.idle":"2023-12-19T18:27:15.571991Z","shell.execute_reply.started":"2023-12-19T18:27:15.564653Z","shell.execute_reply":"2023-12-19T18:27:15.571135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_dim = len(data['Sentiment_encoded'].unique())\nprint(output_dim)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T18:27:15.576161Z","iopub.execute_input":"2023-12-19T18:27:15.576412Z","iopub.status.idle":"2023-12-19T18:27:15.584920Z","shell.execute_reply.started":"2023-12-19T18:27:15.576386Z","shell.execute_reply":"2023-12-19T18:27:15.584059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Instantiate the model with dropout","metadata":{}},{"cell_type":"code","source":"class MultiLabelModelWithDropout(nn.Module):\n    def __init__(self, input_dim, output_dim, dropout_rate=0.5):\n        super(MultiLabelModelWithDropout, self).__init__()\n        self.fc1 = nn.Linear(input_dim, 256)\n        self.dropout = nn.Dropout(p=dropout_rate)\n        self.fc2 = nn.Linear(256, output_dim)\n\n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.fc2(x)\n        return x  # No sigmoid activation here","metadata":{"execution":{"iopub.status.busy":"2023-12-19T18:27:15.585978Z","iopub.execute_input":"2023-12-19T18:27:15.586298Z","iopub.status.idle":"2023-12-19T18:27:15.594940Z","shell.execute_reply.started":"2023-12-19T18:27:15.586266Z","shell.execute_reply":"2023-12-19T18:27:15.594089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Instantiate the model with dropout","metadata":{}},{"cell_type":"code","source":"model = MultiLabelModelWithDropout(input_dim=X_train_tensor.shape[1], output_dim=output_dim, dropout_rate=0.5)\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T18:27:15.596072Z","iopub.execute_input":"2023-12-19T18:27:15.596671Z","iopub.status.idle":"2023-12-19T18:27:15.697177Z","shell.execute_reply.started":"2023-12-19T18:27:15.596639Z","shell.execute_reply":"2023-12-19T18:27:15.696350Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Define the loss function and optimizer","metadata":{}},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()  # Use CrossEntropyLoss for multi-class classification\noptimizer = optim.Adam(model.parameters(), lr=0.01)  # Experiment with different learning rates","metadata":{"execution":{"iopub.status.busy":"2023-12-19T18:27:15.698110Z","iopub.execute_input":"2023-12-19T18:27:15.698371Z","iopub.status.idle":"2023-12-19T18:27:15.702938Z","shell.execute_reply.started":"2023-12-19T18:27:15.698348Z","shell.execute_reply":"2023-12-19T18:27:15.701996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training loop with dropout and validation","metadata":{}},{"cell_type":"code","source":"num_epochs = 180\ntrain_losses = []\nvalid_losses = []\n\nfor epoch in range(num_epochs):\n    # Training\n    model.train()\n    optimizer.zero_grad()\n    predictions = model(X_train_tensor)\n    loss = criterion(predictions, y_train_tensor)\n    \n    # Add L2 regularization\n    l2_reg = 0.001\n    for param in model.parameters():\n        loss += l2_reg * torch.sum(param.pow(2))\n    \n    loss.backward()\n    optimizer.step()\n    \n    # Append the training loss for visualization\n    train_losses.append(loss.item())\n\n    # Validation\n    model.eval()\n    with torch.no_grad():\n        predictions_valid = model(X_valid_tensor)\n        loss_valid = criterion(predictions_valid, y_valid_tensor)\n        valid_losses.append(loss_valid.item())\n    if epoch % 10 == 0:\n        # Print and visualize the training and validation losses\n        print(f\"Epoch [{epoch + 1} / {num_epochs}], Train Loss: {loss.item():.4f}, Valid Loss: {loss_valid.item():.4f}\")\n        torch.cuda.empty_cache()\n","metadata":{"execution":{"iopub.status.busy":"2023-12-19T18:27:15.703984Z","iopub.execute_input":"2023-12-19T18:27:15.704269Z","iopub.status.idle":"2023-12-19T18:27:55.997581Z","shell.execute_reply.started":"2023-12-19T18:27:15.704246Z","shell.execute_reply":"2023-12-19T18:27:55.996748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plot the training and validation losses","metadata":{}},{"cell_type":"code","source":"\nplt.plot(train_losses, label='Training Loss')\nplt.plot(valid_losses, label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Training and Validation Loss Over Time')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-19T18:27:55.998748Z","iopub.execute_input":"2023-12-19T18:27:55.999064Z","iopub.status.idle":"2023-12-19T18:27:56.325022Z","shell.execute_reply.started":"2023-12-19T18:27:55.999037Z","shell.execute_reply":"2023-12-19T18:27:56.324205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Evaluation loop and metric calculation on the test set","metadata":{}},{"cell_type":"code","source":"\nmodel.eval()\nwith torch.no_grad():\n    predictions_test = model(X_test_tensor)\n    probabilities_test = F.softmax(model(X_test_tensor), dim=1)\n    _, predicted_labels_test = torch.max(probabilities_test, 1)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-19T18:27:56.326183Z","iopub.execute_input":"2023-12-19T18:27:56.326456Z","iopub.status.idle":"2023-12-19T18:27:56.335582Z","shell.execute_reply.started":"2023-12-19T18:27:56.326432Z","shell.execute_reply":"2023-12-19T18:27:56.334764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Ensure tensors are on the same device","metadata":{}},{"cell_type":"code","source":"probabilities_test = probabilities_test.to(y_test_tensor.device)\npredicted_labels_test = predicted_labels_test.to(y_test_tensor.device)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-19T18:27:56.336868Z","iopub.execute_input":"2023-12-19T18:27:56.337418Z","iopub.status.idle":"2023-12-19T18:27:56.342319Z","shell.execute_reply.started":"2023-12-19T18:27:56.337386Z","shell.execute_reply":"2023-12-19T18:27:56.341406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Calculate metrics using torchmetrics","metadata":{}},{"cell_type":"code","source":"import torchmetrics\nfrom torchmetrics import F1Score as F1\n\n\nroc_auc = torchmetrics.functional.classification.auroc(probabilities_test, y_test_tensor, average='macro', task='multiclass', num_classes=output_dim)\n\n\nf1_metric = f1 = F1(average='macro', task='multiclass', num_classes=output_dim).to(device)\nf1_test = f1_metric(predicted_labels_test, y_test_tensor)\n\nprint(f\"Test ROC AUC: {roc_auc:.4f}, Test F1 Score: {f1_test:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-19T18:27:56.343374Z","iopub.execute_input":"2023-12-19T18:27:56.343702Z","iopub.status.idle":"2023-12-19T18:27:59.315602Z","shell.execute_reply.started":"2023-12-19T18:27:56.343669Z","shell.execute_reply":"2023-12-19T18:27:59.314675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Conclusion:\n\nThe result is almost the same as using classical models.\n\nI've tried a different epochs quatity and stopped an 180 epochs with lr = 0.01","metadata":{}}]}